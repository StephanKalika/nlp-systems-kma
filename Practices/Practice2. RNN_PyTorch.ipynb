{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIAYbYajk1w9"
      },
      "source": [
        "# Recurrent Neural Networks\n",
        "- IMDB review sentiment classification with RNN\n",
        "  - Last time, we have started sentence classification with CNN and have achieved accuracy over 0.80.\n",
        "  - This time, we try training with RNN to model text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8yy37hEYOEiQ",
        "outputId": "a1f63cc7-ae0b-43ee-ba05-97e8ad36e10b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sqgR-0grNj1p"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewrw93tt2BfV"
      },
      "source": [
        "## 1. Import & process dataset\n",
        "- IMDB review dataset for sentiment analysis\n",
        "  - [source](http://ai.stanford.edu/~amaas/data/sentiment/)\n",
        "  - Let's cheat a while and use dataset provided by Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxDHXFEsf5em",
        "outputId": "807997bf-692d-47d1-d815-8827fb92f18d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "num_words = 10000\n",
        "maxlen = 50\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = num_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMigmAheNj1q",
        "outputId": "7e60b86a-9956-40d5-d26c-100516f02dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 50) (25000, 50) (25000,) (25000,)\n"
          ]
        }
      ],
      "source": [
        "X_train = pad_sequences(X_train, maxlen = maxlen, padding = 'pre')\n",
        "X_test = pad_sequences(X_test, maxlen = maxlen, padding = 'pre')\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(y_train).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbgkiaw6RYos",
        "outputId": "7debf0e1-d85c-4597-f1fd-11594d8f036c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12500\n",
              "0    12500\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOXwAbWYOB8Q",
        "outputId": "5a2f4fc4-64c1-4a70-ac1d-0aee4bfbe377"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(X_train)"
      ],
      "metadata": {
        "id": "66wqmfPqOEn0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gated Recurrent Unit"
      ],
      "metadata": {
        "id": "AEwm3w9pOatC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nznVMdo5edZ"
      },
      "source": [
        "## 2. Creating RNN model and training\n",
        "\n",
        "- Create and train RNN model for sentence classification, with one GRU layer\n",
        "\n",
        "\n",
        "![](http://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Gated_Recurrent_Unit%2C_base_type.svg/440px-Gated_Recurrent_Unit%2C_base_type.svg.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tdmsy2B3weeK"
      },
      "outputs": [],
      "source": [
        "class imdbTrainDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    self.X = X_train\n",
        "    self.y = y_train\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "class imdbTestDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    self.X = X_test\n",
        "    self.y = y_test\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xFBmmDxKw1t2"
      },
      "outputs": [],
      "source": [
        "# create dataset & dataloader instances\n",
        "train_dataset = imdbTrainDataset()\n",
        "test_dataset = imdbTestDataset()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AQawpMRPI7jm"
      },
      "outputs": [],
      "source": [
        "# create RNN with one GRU layer\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, input_dim, num_words, embedding_dim, hidden_size, device):\n",
        "    super(Net, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_size = hidden_size\n",
        "    self.device = device\n",
        "\n",
        "    self.embedding = nn.Embedding(num_words, self.embedding_dim)\n",
        "\n",
        "    # recurrent layer (GRU)\n",
        "    self.rnn = nn.GRU(input_size = self.embedding_dim, hidden_size = hidden_size)\n",
        "    self.dense = nn.Linear(hidden_size, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.embedding(x)                                   # project to word embedding space\n",
        "\n",
        "    h0 = torch.from_numpy(np.zeros((1, x.size(1), self.hidden_size))).float().to(self.device)\n",
        "    x, _ = self.rnn(x, h0)\n",
        "    x = x[:, -1, :]\n",
        "    x = self.dense(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVd5Hc-vNj1r",
        "outputId": "81821f60-8875-49f8-828f-8c6b5c378d5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rP0Gt5E9ajmd"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "DEVICE = torch.device('cuda')\n",
        "INPUT_DIM = maxlen\n",
        "EMBEDDING_DIM = 50\n",
        "HIDDEN_SIZE = 10\n",
        "NUM_WORDS = num_words\n",
        "LEARNING_RATE = 1e-3\n",
        "NUM_EPOCHS = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cPBm8qDrSWsi"
      },
      "outputs": [],
      "source": [
        "model = Net(INPUT_DIM, NUM_WORDS, EMBEDDING_DIM, HIDDEN_SIZE, DEVICE).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()   # do not need softmax layer when using CEloss criterion\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAWpCXdbQbhp",
        "outputId": "57102243-ca3f-479e-a31c-e203148c2783"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (embedding): Embedding(10000, 50)\n",
              "  (rnn): GRU(50, 10)\n",
              "  (dense): Linear(in_features=10, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEBtAPYCFeic",
        "outputId": "b8bf1245-44a2-45c8-9cca-eb7cadda4dbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at 0th epoch: 0.696902723944917\n",
            "Loss at 1th epoch: 0.6864059640436756\n",
            "Loss at 2th epoch: 0.6765898791502933\n",
            "Loss at 3th epoch: 0.6656695370163236\n",
            "Loss at 4th epoch: 0.6542431824669546\n",
            "Loss at 5th epoch: 0.6421763565467329\n",
            "Loss at 6th epoch: 0.6322078090541217\n",
            "Loss at 7th epoch: 0.6235314863068717\n",
            "Loss at 8th epoch: 0.6147601993716493\n",
            "Loss at 9th epoch: 0.6098867405434044\n",
            "Loss at 10th epoch: 0.6021499734143821\n",
            "Loss at 11th epoch: 0.5970303781178533\n",
            "Loss at 12th epoch: 0.592053763720454\n",
            "Loss at 13th epoch: 0.5870070165517379\n",
            "Loss at 14th epoch: 0.5843368575585132\n",
            "Loss at 15th epoch: 0.5805733079204753\n",
            "Loss at 16th epoch: 0.5766064924549084\n",
            "Loss at 17th epoch: 0.5744226584020926\n",
            "Loss at 18th epoch: 0.5725999802959209\n",
            "Loss at 19th epoch: 0.5694818747591\n",
            "Loss at 20th epoch: 0.5683506046022687\n",
            "Loss at 21th epoch: 0.5658779665827751\n",
            "Loss at 22th epoch: 0.5636277002643566\n",
            "Loss at 23th epoch: 0.5620403219850696\n",
            "Loss at 24th epoch: 0.5616967814917467\n",
            "Loss at 25th epoch: 0.5600439895476613\n",
            "Loss at 26th epoch: 0.5583170807483245\n",
            "Loss at 27th epoch: 0.5561586408590784\n",
            "Loss at 28th epoch: 0.5569065064191818\n",
            "Loss at 29th epoch: 0.557229754572012\n"
          ]
        }
      ],
      "source": [
        "# training for NUM_EPOCHS\n",
        "for i in range(NUM_EPOCHS):\n",
        "  temp_loss = []\n",
        "  for (x, y) in train_loader:\n",
        "    x, y = x.long().to(DEVICE), y.to(DEVICE)  # beware that input to embedding should be type 'long'\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y) # y^ - outputs\n",
        "    temp_loss.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(\"Loss at {}th epoch: {}\".format(i, np.mean(temp_loss)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpAJUiHm529m"
      },
      "source": [
        "## 3. Evaluation\n",
        "- Evaluate the trained RNN model with accuracy score\n",
        "  - Store probability of each instance to a list and compare it with true y label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txXH3dknFpSx",
        "outputId": "51b3835c-0f95-4740-d7c9-5b9c03657893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-fff28a038e46>:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  outputs = F.softmax(model(x)).max(1)[-1]       # predicted label\n"
          ]
        }
      ],
      "source": [
        "y_pred, y_true = [], []\n",
        "with torch.no_grad():\n",
        "  for x, y in test_loader:\n",
        "    x, y = x.long().to(DEVICE), y.to(DEVICE)       # beware that input to embedding should be type 'long'\n",
        "    outputs = F.softmax(model(x)).max(1)[-1]       # predicted label\n",
        "    y_true += list(y.cpu().numpy())                # true label\n",
        "    y_pred += list(outputs.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV1s3xf5Frkl",
        "outputId": "448f0b50-521e-484b-a2a9-fce4484c4e38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5966"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# evaluation result\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "P66AjFQeSzVP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy = TP / All samples; Precision = TP / (TP + FP) # type I error; Recall = TN / (TN + FN) # type II error ---- F1-score trade-off between Precision + Recall; ROC AUC"
      ],
      "metadata": {
        "id": "rkOK11ZySI5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku801SlVSzXN",
        "outputId": "0951abcd-bd68-4d8a-fcd5-39f490e49078"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7403, 5097],\n",
              "       [4988, 7512]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iHVc5-ZyS7TR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}